{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('masterchef_data_cleaned.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.keys()\n",
    "US = pd.DataFrame(data['United States'])\n",
    "Canada = pd.DataFrame(data['Canada'])\n",
    "Brazil = pd.DataFrame(data['Brazil'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([US, Canada, Brazil])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(row):\n",
    "    return row['evaluations'][-1] == 'WINNER'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[(df['season'] == 1) & (df['nation'] == 'United States')]['evaluations'])\n",
    "new_df = df.copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['won'] = new_df.apply(winner,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = new_df[new_df['won']]\n",
    "\n",
    "# Function to generate season ID\n",
    "def generate_season_id(row):\n",
    "    country_id = {\"USA\": 1, \"Canada\": 2, \"Brazil\": 3}\n",
    "    \n",
    "    season_id = row['nation'] + str(row['season'])\n",
    "    \n",
    "    return season_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_df['seasonID'] = new_df.apply(generate_season_id, axis=1)\n",
    "winners['seasonID'] = winners.apply(generate_season_id, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['seasonID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners['seasonID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of evaluations in each season\n",
    "\n",
    "def num_episodes(row, evaluations):\n",
    "    if row['won']:\n",
    "        evaluations[row['seasonID']] = len(row['evaluations'])\n",
    "\n",
    "evaluations = {}\n",
    "for i, row in new_df.iterrows():\n",
    "    num_episodes(row, evaluations)\n",
    "print(evaluations)\n",
    "\n",
    "\n",
    "def add_num_eval(row, evaluations):\n",
    "    return evaluations[row['seasonID']]\n",
    "\n",
    "new_df['numEval'] = new_df.apply(add_num_eval, args=(evaluations,), axis=1)\n",
    "new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could use a column saying what place everyone took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some facts about the winners\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_count(df):\n",
    "    a = []\n",
    "    for item in df['evaluations']:\n",
    "        a = np.concatenate([a, item])\n",
    "        \n",
    "    values = np.unique(a, return_counts=True)\n",
    "\n",
    "    values = pd.DataFrame({'counts':values[1], 'values': values[0]})\n",
    "    return values\n",
    "winner_values = eval_count(winners)\n",
    "all_values = eval_count(new_df)\n",
    "\n",
    "sns.barplot(data=winner_values, x='counts', y='values', hue='values', legend=None)\n",
    "plt.show()\n",
    "sns.barplot(data=all_values, x='counts', y='values', hue='values', legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion(row, total_no_elim):\n",
    "    if row['values'] in ['ELIM', 'WINNER', 'RUNNER_UP(S)']:\n",
    "        return 0\n",
    "    return row['counts']/total_no_elim\n",
    "\n",
    "win_total = winner_values['counts'].sum() - winner_values[winner_values['values'].isin(['ELIM', 'WINNER', 'RUNNER_UP(S)'])]['counts'].sum()\n",
    "all_total = all_values['counts'].sum() - all_values[all_values['values'].isin(['ELIM', 'WINNER', 'RUNNER_UP(S)'])]['counts'].sum()\n",
    "\n",
    "\n",
    "all_values['proportion'] = all_values.apply(proportion, args = (all_total,), axis=1)\n",
    "winner_values['proportion'] = winner_values.apply(proportion, args = (win_total,), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_values\n",
    "# doesn't have runner up, wdr, or ban\n",
    "winner_values = pd.concat([winner_values, pd.DataFrame.from_dict({'counts':[0, 0, 0], 'values':['BAN', 'RUNNER_UP(S)', 'WDR'], 'proportion':[0,0,0]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_values.sort_values(by='values')['proportion'] - all_values.sort_values(by='values')['proportion']\n",
    "combined = pd.merge(winner_values, all_values, on='values', suffixes=['_win', '_all'])\n",
    "combined['prop_diff'] = combined['proportion_win'] - combined['proportion_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=combined, x='prop_diff', y='values', hue='values', legend=None)\n",
    "plt.text(0.5, -.18, \"<-Winners had less | Winners had more ->\", ha='center', fontsize=10, transform=plt.gca().transAxes)\n",
    "plt.title('Winner vs all contestants proportion differences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clearest indication of a winner is definitely performance in individual challenges. Winners had individual wins as 18% of their evaluations, while the average competitor (including winners) only had 10% of their evaluations as individual wins. This means winners were nearly twice as likely as all competitors to win challenges.\n",
    "\n",
    "Interestingly, team performance was much less different. If anything, they performed slightly worse than agerage, with a slightly lower proportion of wins.\n",
    "\n",
    "high_i_w\n",
    "0.123167   0.091639\n",
    "\n",
    "win i w\n",
    "0.180352   0.100248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict who will win on after each new evaluation. We can do this a few ways:\n",
    "\n",
    "1. Train a model for each unique number of people.\n",
    "2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
